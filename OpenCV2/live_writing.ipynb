{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5b1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "from torch import nn,optim\n",
    "from torch.optim import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83abbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (8): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (9): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNIST,self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "        nn.Conv2d(1,6,5,padding=2),     #input,output,filter dimensions the padding and stride\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2,stride=2),\n",
    "        \n",
    "        nn.Conv2d(6,16,5,padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2,stride=2),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(400,120),           #16*5*5\n",
    "        nn.Linear(120,84),\n",
    "        nn.Linear(84,10)   #total no.of digits=10\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self,out):\n",
    "        x=self.model(out)\n",
    "        return x\n",
    "    \n",
    "model = MNIST()\n",
    "model.load_state_dict(torch.load('model1.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87982092",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 81\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m \tx1,y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 81\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((canvas, frame))                 \u001b[38;5;66;03m#to display the canvas and frame together\u001b[39;00m\n\u001b[0;32m     85\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScreen_Pen\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mresize(stacked, \u001b[38;5;28;01mNone\u001b[39;00m, fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m, fy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m))     \u001b[38;5;66;03m#minimizing th imagw\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch,torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "load_from_sys = True\n",
    "\n",
    "if load_from_sys:\n",
    "\thsv_value = np.load('hsv_value1.npy')       #value=array([[10,50,70], [ 100, 255, 255]], dtype=int64)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280)                            #width,resolution\n",
    "cap.set(4,720)\n",
    "\n",
    "def prediction(image,model):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  #changing to gray\n",
    "    image=cv2.resize(image,(28,28))             #resizing to 28,28\n",
    "    image=image.astype(np.float32)/255.         #changing to float 32(to send to model)\n",
    "    img = torch.tensor(image).unsqueeze(0).unsqueeze(0).to('cpu')  \n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred=model(img)\n",
    "    return np.argmax(pred)    \n",
    "        \n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)            #filter to smoothen the image\n",
    "\n",
    "canvas = None\n",
    "\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "\n",
    "noise_thresh = 800      \n",
    "while True:\n",
    "\tret, frame = cap.read()     #boolean value,frame read\n",
    "    \n",
    "\tif not ret:\n",
    "\t\tprint('camera cant be opened')\n",
    "\t\tbreak\n",
    "    \n",
    "\tframe = cv2.flip(frame, 1)            # 1 means flipping arond y axis\n",
    "\n",
    "\tif canvas is None:\n",
    "\t\tcanvas = np.zeros_like(frame)         #creating black screen of same size\n",
    "    \n",
    "    \n",
    "\thsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)       #converting to hsv\n",
    "\n",
    "\tif load_from_sys:\n",
    "\t\tlower_range = hsv_value[0]               #70,0,59\n",
    "\t\tupper_range = hsv_value[1]               #179,255,255\n",
    "     \n",
    "\tmask = cv2.inRange(frame,lower_range, upper_range)     #mask of neon orange\n",
    "\n",
    "\tmask = cv2.erode(mask, kernel, iterations = 1)\n",
    "\tmask = cv2.dilate(mask, kernel, iterations = 2)          #erosion and dilation(processing of mask)\n",
    "\n",
    "    \n",
    "\tcontours, heirarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    \n",
    "\tif contours  and cv2.contourArea(max(contours, key = cv2.contourArea)) > noise_thresh:\n",
    "\t\tc = max(contours, key = cv2.contourArea)\n",
    "\t\tx2, y2 ,w, h = cv2.boundingRect(c)\n",
    "\n",
    "\t\tif x1 == 0 and y1 == 0:\n",
    "\t\t\tx1,y1 = x2,y2\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tcanvas = cv2.drawContours(frame,contours,-1,(0,255,0),3) \n",
    "            \n",
    "\n",
    "\n",
    "\telse:\n",
    "        \n",
    "\t\tx1,y1 = 0, 0\n",
    "        \n",
    "    \n",
    "\tframe = cv2.add(frame, canvas)\n",
    "    \n",
    "\tstacked = np.hstack((canvas, frame))                 #to display the canvas and frame together\n",
    "\n",
    "\tcv2.imshow('Screen_Pen', cv2.resize(stacked, None, fx = 0.6, fy = 0.6))     #minimizing th imagw\n",
    "\n",
    "\tif cv2.waitKey(1) == 13:\n",
    "\t\tbreak\n",
    "\n",
    "\t#Clear the canvas when 'c' is pressed\n",
    "    \n",
    "\tif cv2.waitKey(1) & 0xFF == ord('c'):           \n",
    "\t\tcanvas = None\n",
    "\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('o'):\n",
    "\t\ta=prediction(canvas,model)\n",
    "\t\tcv2.putText(canvas, \"Convolution Neural Network:  \" + str(a), (20, 440), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "\t\t\t\t\t255,3)  \n",
    "        \n",
    "        #image,text,coordinates,dtyle,thickness,colour,linetype\n",
    "        \n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8faa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
