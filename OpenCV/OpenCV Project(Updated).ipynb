{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9e003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "from torch import nn,optim\n",
    "from torch.optim import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcbdae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (8): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (9): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNIST,self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "        nn.Conv2d(1,6,5,padding=2),     #input,output,filter dimensions the padding and stride\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2,stride=2),\n",
    "        \n",
    "        nn.Conv2d(6,16,5,padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(2,stride=2),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(400,120),           #16*5*5\n",
    "        nn.Linear(120,84),\n",
    "        nn.Linear(84,10)   #total no.of digits=10\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self,out):\n",
    "        x=self.model(out)\n",
    "        return x\n",
    "    \n",
    "model = MNIST()\n",
    "model.load_state_dict(torch.load('model1.pt'))\n",
    "model.eval()\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch,torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "load_from_sys = True\n",
    "\n",
    "if load_from_sys:\n",
    "\thsv_value = np.load('hsv_value.npy')       #value=array([[  0,  59, 253], [ 87, 255, 255]], dtype=int64)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280)                            #width,resolution\n",
    "cap.set(4,720)\n",
    "\n",
    "\n",
    "\n",
    "#loading the model\n",
    "\n",
    "def prediction(image,model):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  #changing to gray\n",
    "    image=cv2.resize(image,(28,28))             #resizing to 28,28\n",
    "    image=image.astype(np.float32)/255.         #changing to float 32(to send to model)\n",
    "    img = torch.tensor(image).unsqueeze(0).unsqueeze(0).to('cpu')  \n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred=model(img)\n",
    "    return np.argmax(pred)    \n",
    "        \n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)            #filter to smoothen the image\n",
    "\n",
    "canvas = None\n",
    "\n",
    "x1 = 0\n",
    "y1 = 0\n",
    "\n",
    "noise_thresh = 800                     #thrshold value\n",
    "\n",
    "\n",
    "while True:\n",
    "\t_, frame = cap.read()                #boolean value,frame read\n",
    "\tframe = cv2.flip(frame, 1)            # 1 means flipping arond y axis\n",
    "\n",
    "\tif canvas is None:\n",
    "\t\tcanvas = np.zeros_like(frame)         #creating black screen of same size\n",
    "\n",
    "\thsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)       #converting to hsv\n",
    "\n",
    "\tif load_from_sys:\n",
    "\t\tlower_range = hsv_value[0]               #0,59,253\n",
    "\t\tupper_range = hsv_value[1]               #87,255,255\n",
    "\n",
    "\tmask = cv2.inRange(frame,lower_range, upper_range)     #mask of neon orange\n",
    "\n",
    "\tmask = cv2.erode(mask, kernel, iterations = 1)\n",
    "\tmask = cv2.dilate(mask, kernel, iterations = 2)          #erosion and dilation(processing of mask)\n",
    "\n",
    "\tcontours, heirarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)      \n",
    "                   #chain stores x,y of end points\n",
    "                   #rect external only stores eldest,ie,outermost\n",
    "        \n",
    "\tif contours  and cv2.contourArea(max(contours, key = cv2.contourArea)) > noise_thresh:\n",
    "\t\tc = max(contours, key = cv2.contourArea)\n",
    "\t\tx2, y2 ,w, h = cv2.boundingRect(c)                  #creating a bounding box in the mask\n",
    "\n",
    "\t\tif x1 == 0 and y1 == 0:\n",
    "\t\t\tx1,y1 = x2,y2\n",
    "\t\telse:\n",
    "\t\t\tcanvas = cv2.line(canvas, (x1,y1), (x2,y2), [0,255,255], 4)    #creating a green/redline in canvas thickness 4 \n",
    "\n",
    "\t\tx1,y1 = x2,y2\n",
    "\t\n",
    "\telse:\n",
    "\t\tx1,y1 = 0, 0\n",
    "        \n",
    "    \n",
    "\tframe = cv2.add(frame, canvas)\n",
    "\n",
    "\tstacked = np.hstack((canvas, frame))                 #to display the canvas and frame together\n",
    "\tcv2.imshow('Screen_Pen', cv2.resize(stacked, None, fx = 0.6, fy = 0.6))     #minimizing th imagw\n",
    "\n",
    "\tif cv2.waitKey(1) == 13:\n",
    "\t\tbreak\n",
    "\n",
    "\t#Clear the canvas when 'c' is pressed\n",
    "    \n",
    "\tif cv2.waitKey(1) & 0xFF == ord('c'):           \n",
    "\t\tcanvas = None\n",
    "\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "\t\ta=prediction(canvas,model)\n",
    "\t\tcv2.putText(canvas, \"Convolution Neural Network:  \" + str(a), (20, 440), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "\t\t\t\t\t255,3)  \n",
    "        \n",
    "        #image,text,coordinates,dtyle,thickness,colour,linetype\n",
    "        \n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ccc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479eee14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bb9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
